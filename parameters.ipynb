{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb24bb9",
   "metadata": {},
   "source": [
    "Step-1: Importing Necessary Libraries\n",
    "\n",
    "Step-2: Loading The Dataset\n",
    "\n",
    "Step-3: Prepare Dataset We have prepared our dataset from various datasets taking the required attributes that are useful for our case study. We should have a basic understanding of our dataset before moving further.\n",
    "\n",
    "Step-4: Data Preprocessing It involves certain steps like handling missing values, handling outliers, encoding techniques, scaling. Removing null values is most important because the presence of null values will disturb the distribution of data, and may lead to false predictions. There is very less percent of null values in the dataset.\n",
    "\n",
    "Missing values:\n",
    "Imputation is used for replacing missing values. There are few kinds of imputation techniques like Mean imputation, Median imputation, Mode Imputation, Random Sampling imputation, etc. Based on the type of data we have, we can use the required imputation. We have used median imputation to handle missing values.\n",
    "\n",
    "Handling Outliers:\n",
    "Outliers are nothing but an extreme value that deviates from the other observations in the dataset. These outliers are either removed or replaced with their nearest boundary value, either upper boundary or lower boundary value.\n",
    "\n",
    "Label Encoding:\n",
    "Label Encoding is one of the kinds of encoding techniques that will change categorical variables into numerical variables. It is important to convert the labels because our model can only understand numeric data.\n",
    "\n",
    "Step-5: Visualization Visualization using the technique of Correlation in order to understand our data. Data visualization is a powerful technique that helps us to know about the trends, patterns that our data follows. There are different techniques to visualize data, one such method is a correlation. Correlation tells us how one or more are related. If two variables are correlated, then we can tell that both are strongly dependent on each other. The variables that are strongly correlated to the target variable, are said to have more influence on the target variable Correlation can also be visualized using Heatmap. Heatmap is one of the visualizing graphs like Histograms, Boxplots that help us to know our data easily. As human minds are so complex to understand data from numbers, they can easily understand using pictures. Based on the color, we can easily distinguish how the variables are correlated.\n",
    "\n",
    "Light color- Less correlated\n",
    "Medium-light color- correlated\n",
    "Medium color-less strongly correlated\n",
    "Dark color- strongly correlated\n",
    "Based on the above heatmap, we can draw few inferences,\n",
    "\n",
    "Humidity is strongly correlated with the target variable.\n",
    "Next to Humidity, Precipitation also correlated with the target variable.\n",
    "Atmospheric Pressure variable is negatively correlated with a target, which means that the increase in one value may decrease the other value. In short, we can tell that both variables are inversely proportional.\n",
    "Correlation also helps us to remove certain values, as this is one of the feature extraction techniques. If two independent variables are strongly correlated with each other, we can remove any one of the variables. This may not cause any disruption to the dataset.\n",
    "\n",
    "Step-6: Splitting Dataset Dividing the dataset into two sets should be done precisely. The dataset can be divided into the ratio of 80% train set, 20% test set or 70% train set, 30% test set, or any other way. The division of the dataset also affects the accuracy of the training model. A slicing operation can be performed to separate the dataset.We’ve take care while splitting the dataset, assure that the test set must hold an equivalent features as the train set and also the datasets must be statistically meaningful. Considering the independent variables into ‘x’ and therefore the target variable into ‘y’, x = df.iloc [:,:-1].values y = df.iloc [:, 7].values\n",
    "\n",
    "we have divided the dataset into,\n",
    "\n",
    "80% training dataset\n",
    "20% testing dataset\n",
    "Ensure that the dataset is split into train and test sets before training the model. Sometimes we may find more accuracy for our models if we involve both datasets.\n",
    "\n",
    "Step-7: Model Training There are several algorithms in machine learning, but we have chosen only three from them to train our model. In Regression, accuracy can be measured by using R2-Score or Mean Squared Error [MSE] or Root Mean Squared Error [RMSE]. The model should be imported from the Sklearn package and then trained.\n",
    "\n",
    "We have to install the Sklearn package and then import it.\n",
    "\n",
    "CONCLUSION The project aims at the selection of a definite algorithm to predict rainfall concerning the factors that affect rainfall. It is proved that Random Forest Regression Algorithm can be an adaptable strategy for prediction. In this project, we have studied various algorithms and their reaction to each variable for the target variable. Machine Learning can provide us with intelligent models rather than traditional models. The computational power required is also less and manual effort is also reduced. Regression is best for prediction, So, We have considered regression algorithms and one classification algorithm.\n",
    "\n",
    "We have learned different preprocessing techniques that are required in preparing the dataset. The dataset must be free from all kinds of noise, inconsistency, overfitting, and other odds that may affect the performance of the model. We also explored few regression algorithms that can change the predictions with disturbances in input data. The comparative study has made us understand various algorithms effectively.\n",
    "\n",
    "Step 1: Data collection - Define the problem of fake claims and assemble the necessary data attributes to detect fraudulent claims.\n",
    "\n",
    "Step 2: Data preparation - Clean the collected data (remove duplicates, correct errors, deal with missing values, etc…), randomize and visualize data for better performance.\n",
    "\n",
    "Step 3: Split data - Separate the data into training and testing data set to train and test the machine learning system.\n",
    "\n",
    "Step 4: Choose algorithm - Choose the Naïve Bayes algorithm to predict the vehicle insurance claim as fraud or genuine.\n",
    "\n",
    "Step 5: Train the algorithm - Train the Naïve Bayes algorithm with training data set.\n",
    "\n",
    "Step 6: Evaluate the algorithm - Test the algorithm with testing data set.\n",
    "\n",
    "Step 7: Parameter tuning - Tune Naïve Bayes algorithm for new parameter dataset for improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f19da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c54661b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Checking accuracy for Gradient Boosting Classifier\n",
    "et = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd459a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\"splitter\":[\"best\",\"random\"],\n",
    "            \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "           \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "           \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "           \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "           \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv = GridSearchCV(DecisionTreeClassifier(random_state=853), parameters, verbose=1, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b2af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "gcv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11604ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b99ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d9c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the parameters to the final model\n",
    "pred = gcv.best_estimator_.predict(x_test)\n",
    "acc1 =accuracy_score(y_test,pred)\n",
    "print(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7234bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting ROC and AUC curve\n",
    "plot_roc_curve(gcv.best_estimator_,x_test,y_test)\n",
    "plt.title('ROC AUC plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the model\n",
    "model=DecisionTreeClassifier(max_depth=3, max_features='auto',\n",
    "                       min_weight_fraction_leaf=0.1, random_state=853)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters of LogisticRegression\n",
    "parameter= { 'max_iter': [20, 50, 100, 200, 500, 1000],                      \n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],   \n",
    "    'class_weight': ['balanced']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2923ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv = GridSearchCV(LogisticRegression(random_state=587), parameter, verbose=1, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6669a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters of standard vector machine\n",
    "parameter= param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f694eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter={'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "           'fit_intercept' : [True,False],\n",
    "           'normalize' : ['deprecated'], \n",
    "           'precompute' : [True,False],\n",
    "           'copy_X' : [True,False],\n",
    "           'max_iter' : [1000],\n",
    "           'tol' : [0.0001], \n",
    "           'warm_start' : [True,False],\n",
    "           'positive' : [True,False],\n",
    "           'random_state' : [None],\n",
    "           'selection' : ['cyclic', 'random']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a441445",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=lasso, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc44da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest Regressor\n",
    "\n",
    "parameters = {'n_estimators' : [50,100,200],\n",
    "              'criterion' :['mse', 'mae'],\n",
    "              'max_depth' : [4, 6, 8]}\n",
    "GCV=GridSearchCV(rf,parameters,cv=5)\n",
    "GCV.fit(x_train,y_train)\n",
    "Rainfall = RandomForestRegressor(criterion='mse', max_depth=8, n_estimators=100)\n",
    "Rainfall.fit(x_train, y_train)\n",
    "pred = Rainfall.predict(x_test)\n",
    "print('R2_Score:',r2_score(y_test,pred)*100)\n",
    "print(\"RMSE value:\",np.sqrt(metrics.mean_squared_error(y_test, pred)))\n",
    "print('MAE:',metrics.mean_absolute_error(y_test, pred))\n",
    "print('MSE:',metrics.mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning with RandomForestClassifier, parameters of RandomForestClassifier\n",
    "parameters ={'n_estimators':[200], 'criterion':['gini'], \n",
    "             'min_samples_split':[5], 'min_samples_leaf':[2], \n",
    "              'bootstrap':[True],'n_jobs':[-1], 'random_state':[96]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning with gridsearchCV\n",
    "gcv = GridSearchCV(RandomForestClassifier(random_state=96), parameters, verbose=1, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc780d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "gcv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params={'n_neighbors':[5,7,9,11],'weights':['distance','uniform'],'metric':['manhatten','euclidean']}\n",
    "knn_model= GridSearchCV(knn,knn_params,cv=10,n_jobs=-1,verbose=True).fit(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr=SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ee537",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_params={'C':[1,5,10,15,20,30,50],'gamma':[0.001,0.01,0.1,0.2,0.3],'epsilon':[0.01,0.1,1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model=GridSearchCV(svr,svr_params,cv=10,n_jobs=-1,verbose=True).fit(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr=DecisionTreeRegressor()\n",
    "dt_params={'max_depth': np.arange(3,13),'min_samples_split':range(3,11),'min_samples_leaf':range(2,9),\n",
    "           'max_features': np.arange(4,7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92429db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model=GridSearchCV(dtr,dt_params,cv=10,n_jobs=-1,verbose=True).fit(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4542d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr=RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de5c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params={'n_estimators': [70,100,200,400,600],'max_depth':range(2,13),'max_features':['auto','sqrt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79940e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model=GridSearchCV(rfr,rf_params,cv=10,n_jobs=-1,verbose=True).fit(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46dbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "adar=AdaBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_params={'n_estimators': [70,80,100,150,200,250,300,400],'learning_rate': [10 ** x for x in range(-4, 3)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model=GridSearchCV(adar,ada_params,cv=10,n_jobs=-1,verbose=True).fit(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr=GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params={'n_estimators': [100,300,500,700,1000],'max_depth':[2,3,4,5,7,8],'learning_rate': [10 ** x for x in range(-4, 3)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d14175",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model=GridSearchCV(gbr,gb_params,cv=10,n_jobs=-1,verbose=True).fit(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf77df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73d6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params={ 'learning_rate':[0.01,0.1,0.15,0.3],'n_estimators':[50,100,200,500,800,1000,1200],'max_depth':[2,3,4,5,6,7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1df285",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model=GridSearchCV(xgb,xgb_params,cv=10,n_jobs=-1,verbose=True).fit(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d907ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving the parameters list for ETC model.\n",
    "parameter = {'criterion':['gini','entropy'],\n",
    "             'max_depth': [10,12,15,20,22],\n",
    "             'n_estimators':[500,700,1000,1200],\n",
    "             'max_features':['aoto','sqrt','log2'],\n",
    "             'min_samples_split': [2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV=GridSearchCV(ExtraTreesClassifier(),parameter,cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {'max_depth' : range (4,15),\n",
    "             'min_samples_split' : range (2,20,2),\n",
    "             'learning_rate' : np.arange (0.1,0.9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b21f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(gbr, param_grid = grid_param)\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GradientBoostingClassifier(learning_rate= 0.1, max_depth= 6, min_samples_split= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining all the parameters of the respective models\n",
    "Parameter_neighbor={'weights':['uniform', 'distance'],'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "Parameter_dtc={'criterion':[\"gini\", \"entropy\", \"log_loss\"],'splitter':[\"best\", \"random\"],'max_features':[\"auto\", \"sqrt\", \"log2\"]}\n",
    "Parameter_rfc={'criterion' : [\"gini\", \"entropy\", \"log_loss\"],'max_features':[\"sqrt\", \"log2\", None],'class_weight':[\"balanced\", \"balanced_subsample\"]}\n",
    "Parameter_ad={'algorithm':['SAMME', 'SAMME.R']}\n",
    "Parameter_grd={'loss':['log_loss', 'deviance', 'exponential'],'criterion':['friedman_mse', 'squared_error', 'mse'],'max_feat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
